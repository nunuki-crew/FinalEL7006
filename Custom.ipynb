{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "#\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from dataprep import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory created :D\n",
      "Extracting EDF parameters from C:\\Users\\TheSy\\Desktop\\test\\aaaaaaaa\\s001_2015_12_30\\01_tcp_ar\\aaaaaaaa_s001_t000.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 323839  =      0.000 ...  1264.996 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 30 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.10, 30.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Not setting metadata\n",
      "33 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 33 events and 4001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Dropped 1 epoch: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Session</th>\n",
       "      <th>N_Win</th>\n",
       "      <th>Dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>1</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch1.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>1</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch2.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>1</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch3.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>1</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch4.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>1</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch5.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>32</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>32</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>32</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>32</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>32</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Patient Session  N_Win                                                Dir\n",
       "0    aaaaaaaa    s001      1   dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch1.pt\n",
       "1    aaaaaaaa    s001      1   dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch2.pt\n",
       "2    aaaaaaaa    s001      1   dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch3.pt\n",
       "3    aaaaaaaa    s001      1   dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch4.pt\n",
       "4    aaaaaaaa    s001      1   dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch5.pt\n",
       "..        ...     ...    ...                                                ...\n",
       "603  aaaaaaaa    s001     32  dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...\n",
       "604  aaaaaaaa    s001     32  dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...\n",
       "605  aaaaaaaa    s001     32  dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...\n",
       "606  aaaaaaaa    s001     32  dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...\n",
       "607  aaaaaaaa    s001     32  dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...\n",
       "\n",
       "[608 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep(\"C:\\\\Users\\\\TheSy\\\\Desktop\\\\test\", save = True,mode = \"per_channel\", save_dir= \"data\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEEGDataset(Dataset):\n",
    "    def __init__(self, csv_file , root_dir , transform = None, multi = False):\n",
    "        self.loc_df = pd.read_csv(csv_file)\n",
    "        # self.loc_df = loc_df\n",
    "        self.transform = transform\n",
    "        self.root_dir = root_dir\n",
    "        self.multi = multi\n",
    "    def __len__(self,):\n",
    "        return len(self.loc_df)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        if type(idx) == int:\n",
    "            idx = [idx]\n",
    "\n",
    "        batch = []   \n",
    "        for i in idx:\n",
    "            eeg_file = os.path.join(self.root_dir,\n",
    "                                self.loc_df.iloc[i, 3])\n",
    "            eeg = torch.from_numpy(torch.load(eeg_file)) # [0][0]\n",
    "\n",
    "            if self.multi:\n",
    "                eeg= eeg.unsqueeze(0)\n",
    "            batch.append(eeg) \n",
    "        bat = torch.vstack(batch)\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            bat = self.transform(bat)\n",
    "\n",
    "        return bat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFSpliter():\n",
    "    def __init__(self, train_size= 0.8, val_size = 0.2, save = False, seed = 69) -> None:\n",
    "        self.train_size = train_size\n",
    "        self.val_size = val_size\n",
    "        self.save = save\n",
    "        self.seed = seed\n",
    "\n",
    "    def __call__(self, csv_file):\n",
    "        loc_df = pd.read_csv(csv_file)\n",
    "        # loc_df = csv_file\n",
    "        patients = loc_df[\"Patient\"].unique()\n",
    "        np.random.seed(self.seed)\n",
    "        np.random.shuffle(patients)\n",
    "        end_idx = round(len(patients)*self.train_size)\n",
    "\n",
    "        train_patients = patients[:end_idx]\n",
    "        val_patients = patients[end_idx:]\n",
    "        \n",
    "        train_df = pd.DataFrame()\n",
    "        for patient in train_patients:\n",
    "            train_df = pd.concat([train_df,loc_df[loc_df[\"Patient\"] == patient]])\n",
    "\n",
    "        val_df = pd.DataFrame()\n",
    "        for patient in val_patients:\n",
    "            val_df = pd.concat([val_df,loc_df[loc_df[\"Patient\"] == patient]])\n",
    "        \n",
    "        val_df.reset_index(inplace=True, drop= True)\n",
    "        train_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        if self.save:\n",
    "            train_df.to_csv(\"train_feats.csv\", encoding= \"utf-8\")\n",
    "            val_df.to_csv(\"val_feats.csv\", encoding=\"utf-8\")\n",
    "        print(\"CSVs creados\")\n",
    "        return train_df,val_df\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Masking(channel: np.array, window: int= 150):\n",
    "    '''\n",
    "    Set to zero \n",
    "    Input:  -channel = Numpy array\n",
    "            -window = Number of samples to set to zero\n",
    "    Output: Numpy array masked\n",
    "    '''\n",
    "    channel_size = len(channel)\n",
    "    first = np.random.randint(0,channel_size- window)\n",
    "    masked = channel.copy()\n",
    "    masked[first:first+window] = 0\n",
    "\n",
    "    return masked\n",
    "\n",
    "def DCVoltage(channel : np.array, max_magnitude: float = 0.5):\n",
    "    ''' \n",
    "    Add a DC component between [-max_mangitude, max_magnitude]\n",
    "    Input:  -channel = Numpy array\n",
    "            -max_magnitude = max value to be added\n",
    "    Output: Numpy array \n",
    "    '''\n",
    "    dc_comp = (np.random.random(1)*2 - 1)*max_magnitude\n",
    "    dispaced_channel = channel + dc_comp\n",
    "    return dispaced_channel    \n",
    "\n",
    "def GaussianNoise(channel: np.array, std: float = 0.2):\n",
    "    '''\n",
    "    Add Gaussian Noise with zero mean and std deviation\n",
    "    Input:  -channel = Numpy array\n",
    "            -std = Gaussian std\n",
    "    Output: Channel with additive gaussian noise added\n",
    "    '''\n",
    "    channel_size = len(channel)\n",
    "    noise = np.random.normal(loc = 0, scale= std, size= channel_size)\n",
    "    noisy_channel = channel + noise\n",
    "    return noisy_channel\n",
    "\n",
    "def Time_Shift(channel: np.array, min_shift: int = 0, max_shift: int = 50 ):\n",
    "    ''' \n",
    "    Shifts the channel n samples between min_shift and max_shift using reflection pad\n",
    "    Input:  -channel = Numpy array\n",
    "            -min_shift = Min number of samples to shift\n",
    "            -max_shhift = Max number of samples to shift  \n",
    "    Output: Shifted channel\n",
    "    '''\n",
    "    n_shift = np.random.randint(min_shift,max_shift)\n",
    "    channel_size = len(channel)\n",
    "    padded_array = np.pad(channel,pad_width= n_shift, mode = \"reflect\")\n",
    "    right_left = np.random.choice((0,2))\n",
    "    shifted_array = padded_array[n_shift*right_left:channel_size + n_shift*right_left]\n",
    "    return shifted_array\n",
    "def Amplitude(channel :np.array, max_amplitude: float = 1.5):\n",
    "    '''\n",
    "    Modifies the ampliude of the channel values between [1+max_amplitude,1-max_amplitude]\n",
    "    Input:  -channel = Numpy array\n",
    "            -max_amplitude = Max aplitude to add\n",
    "    Output: Boosted channel\n",
    "    '''\n",
    "    amplitude = 1 + ((np.random.random(1)*2 -1) * max_amplitude)\n",
    "    boosted_channel = channel*amplitude\n",
    "    return boosted_channel\n",
    "\n",
    "def Permutation(channel: np.array, win_samples: int = 4):\n",
    "    '''\n",
    "    Permutates the arrays by secuences of win_samples len\n",
    "    Ensure its divisible by the total len of the array or the len of the output secuence will be wrong\n",
    "    Input:  -channel = Numpu array\n",
    "            -win_samples = Number of samples per secuences (N_sec = len(channel)// win_samples)\n",
    "    Output: Permutated secuence\n",
    "    '''\n",
    "\n",
    "    n_seqs = len(channel)// win_samples\n",
    "    random_idx = np.random.choice(np.arange(0,n_seqs, 1), n_seqs, replace=False ) \n",
    "    permutated = np.concatenate([channel[win_samples*i: win_samples*(i+1)] for i in random_idx])\n",
    "    return permutated\n",
    "def Temporal_Invertion(channel: np.array):\n",
    "    ''' \n",
    "    Return the array reversed\n",
    "    Input:  -channel = Numpy array\n",
    "    Output: Reversed array\n",
    "    '''\n",
    "    reversed = channel[::-1]\n",
    "    return reversed\n",
    "\n",
    "def Negation(channel: np.array):\n",
    "    '''\n",
    "    Inverts the full array\n",
    "    Input: -channel = Numpy array\n",
    "    Output: Inverted array\n",
    "    '''\n",
    "    negated = channel * (-1)\n",
    "    return negated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentation set\n",
    "AUGMENTATIONS = [Negation,\n",
    "                 Time_Shift,\n",
    "                 Amplitude,\n",
    "                 DCVoltage,\n",
    "                 GaussianNoise,\n",
    "                 Temporal_Invertion,\n",
    "                 Permutation,\n",
    "                 Masking]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmentations(nn.Module):\n",
    "    def __init__(self, n_aug, multi = False, augmentations = None) -> None:\n",
    "        self.n_aug = n_aug\n",
    "        self.multi = multi\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "    def __call__(self,batch):\n",
    "        xbar_batch = []\n",
    "        xhat_batch = []\n",
    "\n",
    "        rbar_idxs = np.random.choice(np.arange(0,len(self.augmentations),1),size=self.n_aug, replace= False)\n",
    "        rhat_idxs = np.random.choice(np.arange(0,len(self.augmentations),1),size=self.n_aug, replace= False)\n",
    "\n",
    "        batch = batch.numpy()\n",
    "\n",
    "        for channel in batch:\n",
    "            xbar = channel\n",
    "            xhat = channel\n",
    "            for i in rbar_idxs:\n",
    "                xbar = self.augmentations[i](xbar)\n",
    "                # print(self.augmentations[i])\n",
    "            for j in rhat_idxs:\n",
    "                xhat = self.augmentations[j](xhat)\n",
    "                # print(self.augmentations[j])\n",
    "            xbar_batch.append(torch.from_numpy(xbar[:4000].copy()))\n",
    "            xhat_batch.append(torch.from_numpy(xhat[0:4000].copy()))\n",
    "        \n",
    "        xbar_batch = torch.vstack(xbar_batch)\n",
    "        xhat_batch = torch.vstack(xhat_batch)\n",
    "\n",
    "        return xbar_batch,xhat_batch\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_df = pd.DataFrame(columns= [\"Patient\", \"Session\",\"N_Win\", \"Dir\"], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"C:\\\\Users\\\\TheSy\\\\Desktop\\\\FinalEL7006\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esta cosa agrega elementos al dataframe vacio, prueba cambiando el primer elemento de la lista \n",
    "#Para agregar distintos pacientes c:\n",
    "loc_df.loc[len(loc_df)] = [\"aaal\",\"session_id\",1,\"LSTMData-0.001.pt\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Session</th>\n",
       "      <th>N_Win</th>\n",
       "      <th>Dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaal</td>\n",
       "      <td>session_id</td>\n",
       "      <td>1</td>\n",
       "      <td>LSTMData-0.001.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Patient     Session  N_Win                Dir\n",
       "0    aaal  session_id      1  LSTMData-0.001.pt"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVs creados\n"
     ]
    }
   ],
   "source": [
    "spliter = DFSpliter()\n",
    "train ,val = spliter(loc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Patient     Session  N_Win                Dir\n",
       " 0     aaap  session_id      1  LSTMData-0.001.pt\n",
       " 1     aaap  session_id      1  LSTMData-0.001.pt\n",
       " 2     aaap  session_id      1  LSTMData-0.001.pt\n",
       " 3     aaai  session_id      1  LSTMData-0.001.pt\n",
       " 4     aaai  session_id      1  LSTMData-0.001.pt\n",
       " 5     aaai  session_id      1  LSTMData-0.001.pt\n",
       " 6     aaaa  session_id      1  LSTMData-0.001.pt\n",
       " 7     aaaa  session_id      1  LSTMData-0.001.pt\n",
       " 8     aaaa  session_id      1  LSTMData-0.001.pt\n",
       " 9     aaal  session_id      1  LSTMData-0.001.pt\n",
       " 10    aaal  session_id      1  LSTMData-0.001.pt\n",
       " 11    aaal  session_id      1  LSTMData-0.001.pt\n",
       " 12    aaax  session_id      1  LSTMData-0.001.pt\n",
       " 13    aaax  session_id      1  LSTMData-0.001.pt\n",
       " 14    aaax  session_id      1  LSTMData-0.001.pt,\n",
       "   Patient     Session  N_Win                Dir\n",
       " 0    aaag  session_id      1  LSTMData-0.001.pt\n",
       " 1    aaag  session_id      1  LSTMData-0.001.pt\n",
       " 2    aaag  session_id      1  LSTMData-0.001.pt)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train,val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomEEGDataset(\"prep_channels.csv\",root_path, multi=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() argument must be str, bytes, or os.PathLike object, not 'int64'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\TheSy\\Desktop\\FinalEL7006\\Custom.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataset[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;32mc:\\Users\\TheSy\\Desktop\\FinalEL7006\\Custom.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m batch \u001b[39m=\u001b[39m []   \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     eeg_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot_dir,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc_df\u001b[39m.\u001b[39;49miloc[i, \u001b[39m3\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     eeg \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(torch\u001b[39m.\u001b[39mload(eeg_file)) \u001b[39m# [0][0]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmulti:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\ntpath.py:143\u001b[0m, in \u001b[0;36mjoin\u001b[1;34m(path, *paths)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[39mreturn\u001b[39;00m result_drive \u001b[39m+\u001b[39m result_path\n\u001b[0;32m    142\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mAttributeError\u001b[39;00m, \u001b[39mBytesWarning\u001b[39;00m):\n\u001b[1;32m--> 143\u001b[0m     genericpath\u001b[39m.\u001b[39;49m_check_arg_types(\u001b[39m'\u001b[39;49m\u001b[39mjoin\u001b[39;49m\u001b[39m'\u001b[39;49m, path, \u001b[39m*\u001b[39;49mpaths)\n\u001b[0;32m    144\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\genericpath.py:152\u001b[0m, in \u001b[0;36m_check_arg_types\u001b[1;34m(funcname, *args)\u001b[0m\n\u001b[0;32m    150\u001b[0m         hasbytes \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 152\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfuncname\u001b[39m}\u001b[39;00m\u001b[39m() argument must be str, bytes, or \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    153\u001b[0m                         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mos.PathLike object, not \u001b[39m\u001b[39m{\u001b[39;00ms\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mif\u001b[39;00m hasstr \u001b[39mand\u001b[39;00m hasbytes:\n\u001b[0;32m    155\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt mix strings and bytes in path components\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: join() argument must be str, bytes, or os.PathLike object, not 'int64'"
     ]
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader(dataset=dataset,batch_size=4,shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dataset.__getitem__([0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 4001])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = Augmentations(3,augmentations=AUGMENTATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19, 4000]) torch.Size([19, 4000])\n"
     ]
    }
   ],
   "source": [
    "aug_batch = augment(batch)\n",
    "print(aug_batch[0].shape,aug_batch[1].shape)\n",
    "\n",
    "# x,y = aug_batch\n",
    "# z1 = model(x)\n",
    "# z2 = model(y)\n",
    "# loss(z1,z2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
