{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Módulo de preprocesamiento \n",
    "Ammi Beltrán & Fernanda Borja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importado de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\TheSy\\Desktop\\FinalEL7006\\dataprep.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/dataprep.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcopy\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/dataprep.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/dataprep.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mne\n",
    "import glob\n",
    "#\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "# import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea el path de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory created :D\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "    print(\"Data directory created :D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dirección del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDFDIR = \"D:\\\\OneDrive\\\\OneDrive - Universidad de Chile\\\\Semestre X\\\\Inteligencia\\\\Proyecto\\\\dataset\\\\tuh_eeg\"\n",
    "EDFDIR = \"c:\\\\Users\\\\TheSy\\\\Desktop\\\\tuh_eeg\"\n",
    "# files = glob.glob(EDFDIR + '/**/*.edf', recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos MNE\n",
    "data = mne.io.read_raw_edf(files[0])\n",
    "raw_data = data.get_data()\n",
    "info = data.info\n",
    "channels = data.ch_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones\n",
    "* Una vez funcione mover a .py y traer como librería "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccion de canales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_select(data, channels):\n",
    "    '''\n",
    "    Selects channels from array \n",
    "    '''\n",
    "    extracted = data.pick(channels, exclude=\"bads\")\n",
    "    return extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clipeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(data, channels,max= 500e-6):\n",
    "    def cliper(array):\n",
    "        for i in range(len(array)):\n",
    "            if abs(array[i]) > max:\n",
    "                array[i] = math.copysign(max,array[i])\n",
    "        return array\n",
    "    data.apply_function(cliper, picks=channels, channel_wise= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eeg_filter(data, lfreq = 0.3, hfreq= 80):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    data_copy = copy.copy(data)\n",
    "    filtered = data_copy.filter(l_freq = lfreq,\n",
    "                                h_freq = hfreq,\n",
    "                                method = \"iir\"\n",
    "                                )\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corte de primero minuto y de max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_crop(data, tin = 60, tfin = 12*60):\n",
    "    ''' \n",
    "    Cut the channels from the second \"tin\" to \"tfin\"\n",
    "    '''\n",
    "    data_copy = copy.copy(data)\n",
    "    croped = data_copy.crop(tmin = tin, tmax = min(tfin, int(data.times[-1])))\n",
    "    return croped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marcado de épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eventos\n",
    "def get_epochs(data, channels, window = 20.0):\n",
    "    ''' \n",
    "    window es la ventana de tiempo\n",
    "    '''\n",
    "    data_copy = copy.copy(data)\n",
    "    # Create events\n",
    "    events = mne.make_fixed_length_events(data_copy, duration = window, first_samp = True)\n",
    "    # Divide accordingly\n",
    "    picks = channels\n",
    "    epochs = mne.Epochs(raw = data_copy, events = events, picks = picks, preload = True,\n",
    "                        tmin = 0., tmax = window, baseline = None,\n",
    "                        flat = dict(eeg = 1e-6))\n",
    "    \n",
    "    epochs.drop(-1,reason = \"Unfixed duration\")\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(epoch, freq = 200):\n",
    "    ''' \n",
    "    Downsamples the data given by a factor\n",
    "    En nuestro caso, down corresponde a (frecuencia que queremos)/(frecuencia actual)\n",
    "    '''\n",
    "    down = epoch.resample(freq, npad = \"auto\")\n",
    "    return down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(epochs):\n",
    "    obj = mne.decoding.Scaler(info = epochs.info, scalings='mean')\n",
    "    values = obj.fit_transform(epochs.get_data())\n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(path):\n",
    "    ''' \n",
    "    Pipeline de procesamiento c:\n",
    "    - Canales c:\n",
    "    - Filtrado c:\n",
    "    - Downsample c:\n",
    "    - Crop temporal (primer minuto y a los 11 minutos) c:  \n",
    "    - Segmentación c:\n",
    "    - Normalización c:\n",
    "    '''\n",
    "\n",
    "    files = glob.glob(path + '/**/*.edf', recursive = True)\n",
    "    # windows = np.empty() EVALUAR\n",
    "    windows = []\n",
    "    for i in range(0, len(files)):\n",
    "        data = mne.io.read_raw_edf(files[i], preload=True)\n",
    "        # raw_data = data.get_data()\n",
    "        # info = data.info\n",
    "        channels = data.ch_names[:21]\n",
    "        # Pipeline\n",
    "        # \n",
    "        # mapping = rename_channels(data)\n",
    "\n",
    "        # data.rename_channels(data.info, mapping)\n",
    "        # data.rename_channels(mapping)\n",
    "\n",
    "        # try:\n",
    "        channel_data = channel_select(data, channels)\n",
    "        clip(channel_data,channels)\n",
    "        # except:\n",
    "        #     channel_data = channel_select(data, CHANNELS_LE)\n",
    "        #     ch = CHANNELS_LE\n",
    "        if(int(data.times[-1]) < 100):\n",
    "            continue\n",
    "        filtered = eeg_filter(channel_data)\n",
    "        trimmed_data = temporal_crop(filtered)\n",
    "        epochs = get_epochs(trimmed_data, channels)\n",
    "        down_data = downsample(epochs)\n",
    "        norm_data = normalization(down_data)\n",
    "        #\n",
    "        windows.append(norm_data)\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient = glob.glob(EDFDIR + '/**')\n",
    "# patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "win = preprocessing(EDFDIR)\n",
    "win"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channels we want\n",
    "\n",
    "def rename_channels(data):\n",
    "    # info = data.info\n",
    "    original = data.ch_names\n",
    "    new = copy.copy(original)\n",
    "    res = {}\n",
    "    for ch in new:\n",
    "        \n",
    "        isin = False\n",
    "        for n in CHANNELS:\n",
    "            if n in ch:\n",
    "                res[ch] = n\n",
    "                isin = True\n",
    "                break\n",
    "\n",
    "        if not isin:\n",
    "            res[ch] = ch\n",
    "            \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EDFprep(edf):\n",
    "    '''\n",
    "    Pipeline\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(path, save = False, save_dir = \"data\", sep = \"\\\\\"):\n",
    "    ''' \n",
    "    Lectura de todos los edfs de cada paciente, guardado de ventanas temporales y csv de direcciones\n",
    "\n",
    "    Inputs:\n",
    "        -path\n",
    "    Output:\n",
    "        -dir_csv: csv con todos los datos de guardado de las ventanas de cada edf.    \n",
    "    '''\n",
    "    LEN_PAT = 8\n",
    "    SESION_LEN = 15\n",
    "    loc_df = pd.DataFrame(columns= [\"Patient\", \"Session\",\"N_Win\", \"Dir\"], )\n",
    "\n",
    "    if save:\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "            print(\"Data directory created :D\")\n",
    "    \n",
    "\n",
    "    patient_path = glob.glob(EDFDIR + '/**')\n",
    "    for patient in patient_path:\n",
    "\n",
    "        #Para guardar la id en el DF\n",
    "        patient_id = patient[-LEN_PAT:]\n",
    "        \n",
    "        sessions = glob.glob(patient + '/**')\n",
    "        for session in sessions:\n",
    "\n",
    "                    \n",
    "            #Para guardar la sesion correspondiente\n",
    "            session_id = session[-SESION_LEN:-(SESION_LEN - 4)]\n",
    "\n",
    "            if save:\n",
    "                if not os.path.exists(save_dir + sep + session_id):\n",
    "                    os.makedirs(save_dir + sep + session_id)\n",
    "\n",
    "            edfs = glob.glob(session+ \"/**/*.edf\")\n",
    "            for edf in edfs:\n",
    "\n",
    "                raw = mne.io.read_raw_edf(edf,preload=True)\n",
    "                data = EDFprep(raw)\n",
    "                \n",
    "                for i in range(len(data)):\n",
    "                    sdir = f\"{save_dir}{sep}{patient_id}{sep}{session_id}{sep}w{i+1}.pt\"\n",
    "                    loc_df.loc[len(loc_df)] = [patient_id,session_id,i+1,sdir]\n",
    "\n",
    "                    if save:\n",
    "                        torch.save(data[i],f\"{save_dir}{sep}{session}{sep}{patient_id}_{session}_w{i+1}.pt\")\n",
    "\n",
    "    if save:\n",
    "        pass\n",
    "        #Guardar df como csv\n",
    "\n",
    "                \n",
    "    return loc_df\n",
    "            \n",
    "    [\"aaaa\",\"s001\",7,\"data/s001/aaaa_s001_w7.pt\"]\n",
    "\n",
    "    win = [[[]]]\n",
    "        \n",
    "        \n",
    "    win = torch.load(\"w7.pt\")\n",
    "\n",
    "    Batch = [].cat(win)\n",
    "\n",
    "    # windows = []\n",
    "    # for i in range(0, len(files)):\n",
    "    #     data = mne.io.read_raw_edf(files[i], preload=True)\n",
    "\n",
    "    #     channels = data.ch_names[:21]\n",
    "      \n",
    "    #     channel_data = channel_select(data, channels)\n",
    "\n",
    "    #     clip(channel_data,channels)\n",
    "\n",
    "    #     if(int(data.times[-1]) < 100):\n",
    "    #         continue\n",
    "\n",
    "    #     filtered = eeg_filter(channel_data)\n",
    "    #     trimmed_data = temporal_crop(filtered)\n",
    "    #     epochs = get_epochs(trimmed_data, channels)\n",
    "    #     down_data = downsample(epochs)\n",
    "    #     norm_data = normalization(down_data)\n",
    "        \n",
    "    #     windows.append(norm_data)\n",
    "    # return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s001\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s004\n",
      "s005\n",
      "s006\n",
      "s007\n",
      "s008\n",
      "s009\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s004\n",
      "s005\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s004\n",
      "s005\n",
      "s006\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s004\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s004\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s004\n",
      "s005\n",
      "s006\n",
      "s007\n",
      "s009\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s001\n",
      "s002\n",
      "s001\n",
      "s002\n",
      "s001\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s004\n",
      "s005\n",
      "s001\n",
      "s002\n",
      "s001\n",
      "s002\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s002\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s002\n",
      "s001\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s004\n",
      "s005\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s002\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s004\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s004\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s001\n",
      "s002\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s002\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s004\n",
      "s005\n",
      "s006\n",
      "s007\n",
      "s008\n",
      "s009\n",
      "s010\n",
      "s011\n",
      "s012\n",
      "s013\n",
      "s014\n",
      "s015\n",
      "s016\n",
      "s017\n",
      "s018\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s002\n",
      "s001\n",
      "s001\n",
      "s003\n",
      "s004\n",
      "s005\n",
      "s006\n",
      "s007\n",
      "s008\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s004\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s002\n",
      "s001\n",
      "s002\n",
      "s001\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s004\n",
      "s005\n",
      "s006\n",
      "s007\n",
      "s008\n",
      "s009\n",
      "s010\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s004\n",
      "s001\n",
      "s001\n",
      "s002\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s004\n",
      "s001\n",
      "s001\n",
      "s002\n",
      "s003\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n",
      "s001\n"
     ]
    }
   ],
   "source": [
    "prep(EDFDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_csv = pd.DataFrame(columns= [\"Patient\", \"Nro_Set\", \"N_samp\", \"Dir\"], )\n",
    "# p1 = {\"Patient\": \"aaaa\", \"Nro_Set\": \"s000\", \"N_samp\": 1, \"Dir\": \"c:\\\\UwU\"}\n",
    "dir_csv.loc[len(dir_csv)] = [\"aaaa\",\"s000\",1,\"c:\\\\UwU\"]\n",
    "# dir_csv.loc[1] = [\"aaab\",\"s000\",1,\"c:\\\\UwU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Nro_Set</th>\n",
       "      <th>N_samp</th>\n",
       "      <th>Dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaaa</td>\n",
       "      <td>s000</td>\n",
       "      <td>1</td>\n",
       "      <td>c:\\UwU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Patient Nro_Set  N_samp     Dir\n",
       "0    aaaa    s000       1  c:\\UwU"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_csv.loc[len(dir_csv)] = [\"aaaa\",\"s000\",1,\"c:\\\\UwU\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
