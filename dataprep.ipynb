{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Módulo de preprocesamiento \n",
    "Ammi Beltrán & Fernanda Borja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importado de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.0-cp310-cp310-win_amd64.whl (9.2 MB)\n",
      "     ---------------------------------------- 9.2/9.2 MB 25.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\thesy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.24.3)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\thesy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.10.1)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "     ---------------------------------------- 302.2/302.2 kB ? eta 0:00:00\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.0 threadpoolctl-3.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: C:\\Users\\TheSy\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# ! pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import glob\n",
    "#\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea el path de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "    print(\"Data directory created :D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dirección del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDFDIR = \"D:\\\\OneDrive\\\\OneDrive - Universidad de Chile\\\\Semestre X\\\\Inteligencia\\\\Proyecto\\\\dataset\\\\tuh_eeg\"\n",
    "EDFDIR = \"c:\\\\Users\\\\TheSy\\\\Desktop\\\\tuh_eeg\"\n",
    "files = glob.glob(EDFDIR + '/**/*.edf', recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\TheSy\\Desktop\\tuh_eeg\\aaaaaaaa\\s001_2015_12_30\\01_tcp_ar\\aaaaaaaa_s001_t000.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    }
   ],
   "source": [
    "# Usamos MNE\n",
    "data = mne.io.read_raw_edf(files[0])\n",
    "raw_data = data.get_data()\n",
    "info = data.info\n",
    "channels = data.ch_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones\n",
    "* Una vez funcione mover a .py y traer como librería "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccion de canales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_select(data, channels):\n",
    "    '''\n",
    "    Selects channels from array \n",
    "    '''\n",
    "    extracted = data.pick(channels, exclude=\"bads\")\n",
    "    return extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clipeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(data, channels,max= 500e-6):\n",
    "    def cliper(array):\n",
    "        for i in range(len(array)):\n",
    "            if abs(array[i]) > max:\n",
    "                array[i] = math.copysign(max,array[i])\n",
    "        return array\n",
    "    data.apply_function(cliper, picks=channels, channel_wise= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eeg_filter(data, lfreq = 0.3, hfreq= 80):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    data_copy = copy.copy(data)\n",
    "    filtered = data_copy.filter(l_freq = lfreq,\n",
    "                                h_freq = hfreq,\n",
    "                                method = \"iir\"\n",
    "                                )\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corte de primero minuto y de max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_crop(data, tin = 60, tfin = 12*60):\n",
    "    ''' \n",
    "    Cut the channels from the second \"tin\" to \"tfin\"\n",
    "    '''\n",
    "    data_copy = copy.copy(data)\n",
    "    croped = data_copy.crop(tmin = tin, tmax = min(tfin, int(data.times[-1])))\n",
    "    return croped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marcado de épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eventos\n",
    "def get_epochs(data, channels, window = 20.0):\n",
    "    ''' \n",
    "    window es la ventana de tiempo\n",
    "    '''\n",
    "    data_copy = copy.copy(data)\n",
    "    # Create events\n",
    "    events = mne.make_fixed_length_events(data_copy, duration = window, first_samp = True)\n",
    "    # Divide accordingly\n",
    "    picks = channels\n",
    "    epochs = mne.Epochs(raw = data_copy, events = events, picks = picks, preload = True,\n",
    "                        tmin = 0., tmax = window, baseline = None,\n",
    "                        flat = dict(eeg = 1e-6))\n",
    "    \n",
    "    epochs.drop(-1,reason = \"Unfixed duration\")\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(epoch, freq = 200):\n",
    "    ''' \n",
    "    Downsamples the data given by a factor\n",
    "    En nuestro caso, down corresponde a (frecuencia que queremos)/(frecuencia actual)\n",
    "    '''\n",
    "    down = epoch.resample(freq, npad = \"auto\")\n",
    "    return down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(epochs):\n",
    "    obj = mne.decoding.Scaler(info = epochs.info, scalings='mean')\n",
    "    values = obj.fit_transform(epochs.get_data())\n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(path):\n",
    "    ''' \n",
    "    Pipeline de procesamiento c:\n",
    "    - Canales c:\n",
    "    - Filtrado c:\n",
    "    - Downsample c:\n",
    "    - Crop temporal (primer minuto y a los 11 minutos) c:  \n",
    "    - Segmentación c:\n",
    "    - Normalización c:\n",
    "    '''\n",
    "\n",
    "    files = glob.glob(path + '/**/*.edf', recursive = True)\n",
    "    # windows = np.empty() EVALUAR\n",
    "    windows = []\n",
    "    for i in range(0, len(files)):\n",
    "        data = mne.io.read_raw_edf(files[i], preload=True)\n",
    "        # raw_data = data.get_data()\n",
    "        # info = data.info\n",
    "        channels = data.ch_names[:21]\n",
    "        # Pipeline\n",
    "        # \n",
    "        # mapping = rename_channels(data)\n",
    "\n",
    "        # data.rename_channels(data.info, mapping)\n",
    "        # data.rename_channels(mapping)\n",
    "\n",
    "        # try:\n",
    "        channel_data = channel_select(data, channels)\n",
    "        clip(channel_data,channels)\n",
    "        # except:\n",
    "        #     channel_data = channel_select(data, CHANNELS_LE)\n",
    "        #     ch = CHANNELS_LE\n",
    "        if(int(data.times[-1]) < 100):\n",
    "            continue\n",
    "        filtered = eeg_filter(channel_data)\n",
    "        trimmed_data = temporal_crop(filtered)\n",
    "        epochs = get_epochs(trimmed_data, channels)\n",
    "        down_data = downsample(epochs)\n",
    "        norm_data = normalization(down_data)\n",
    "        #\n",
    "        windows.append(norm_data)\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient = glob.glob(EDFDIR + '/**')\n",
    "# patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "win = preprocessing(EDFDIR)\n",
    "win"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channels we want\n",
    "\n",
    "def rename_channels(data):\n",
    "    # info = data.info\n",
    "    original = data.ch_names\n",
    "    new = copy.copy(original)\n",
    "    res = {}\n",
    "    for ch in new:\n",
    "        \n",
    "        isin = False\n",
    "        for n in CHANNELS:\n",
    "            if n in ch:\n",
    "                res[ch] = n\n",
    "                isin = True\n",
    "                break\n",
    "\n",
    "        if not isin:\n",
    "            res[ch] = ch\n",
    "            \n",
    "    return res\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
