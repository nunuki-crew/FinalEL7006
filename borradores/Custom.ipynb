{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision import transforms, utils\n",
    "from dataprep import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory created :D\n",
      "Extracting EDF parameters from C:\\Users\\TheSy\\Desktop\\tests\\aaaaaaaa\\s001_2015_12_30\\01_tcp_ar\\aaaaaaaa_s001_t000.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 323839  =      0.000 ...  1264.996 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 30 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.10, 30.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Not setting metadata\n",
      "33 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 33 events and 4001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Dropped 1 epoch: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Session</th>\n",
       "      <th>N_Win</th>\n",
       "      <th>Dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>1</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch1.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>1</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch2.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>1</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch3.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>1</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch4.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>1</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch5.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>32</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>32</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>32</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>32</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>32</td>\n",
       "      <td>dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Patient Session  N_Win  \\\n",
       "0    aaaaaaaa    s001      1   \n",
       "1    aaaaaaaa    s001      1   \n",
       "2    aaaaaaaa    s001      1   \n",
       "3    aaaaaaaa    s001      1   \n",
       "4    aaaaaaaa    s001      1   \n",
       "..        ...     ...    ...   \n",
       "603  aaaaaaaa    s001     32   \n",
       "604  aaaaaaaa    s001     32   \n",
       "605  aaaaaaaa    s001     32   \n",
       "606  aaaaaaaa    s001     32   \n",
       "607  aaaaaaaa    s001     32   \n",
       "\n",
       "                                                   Dir  \n",
       "0     dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch1.pt  \n",
       "1     dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch2.pt  \n",
       "2     dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch3.pt  \n",
       "3     dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch4.pt  \n",
       "4     dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch5.pt  \n",
       "..                                                 ...  \n",
       "603  dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...  \n",
       "604  dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...  \n",
       "605  dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...  \n",
       "606  dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...  \n",
       "607  dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w32_ch1...  \n",
       "\n",
       "[608 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep(\"C:\\\\Users\\\\TheSy\\\\Desktop\\\\tests\", save = True, mode = \"per_channel\", save_dir=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEEGDataset(Dataset):\n",
    "    def __init__(self, csv_file , root_dir , transform = None, multi = False, ):\n",
    "\n",
    "        try:\n",
    "            self.loc_df = pd.read_csv(os.path.join(root_dir,csv_file)).drop(labels=\"Unnamed: 0\", axis = 1)\n",
    "        except:\n",
    "            self.loc_df = pd.read_csv(os.path.join(root_dir,csv_file))\n",
    "        # self.loc_df = loc_df\n",
    "        self.transform = transform\n",
    "        self.root_dir = root_dir\n",
    "        self.multi = multi\n",
    "    def __len__(self,):\n",
    "        return len(self.loc_df)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        if type(idx) == int:\n",
    "            idx = [idx]\n",
    "\n",
    "        batch = []   \n",
    "        for i in idx:\n",
    "            eeg_file = os.path.join(self.root_dir,\n",
    "                                self.loc_df.iloc[i, 3])\n",
    "            # eeg = torch.from_numpy(torch.load(eeg_file)) # [0][0]\n",
    "            eeg = torch.load(eeg_file)\n",
    "\n",
    "            if self.multi:\n",
    "                eeg= eeg.unsqueeze(0)\n",
    "            batch.append(eeg) \n",
    "        bat = torch.vstack(batch)\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            bat = self.transform(bat)\n",
    "\n",
    "        return bat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"C:\\\\Users\\\\TheSy\\\\Desktop\\\\FinalEL7006\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = CustomEEGDataset(\"prep_channels.csv\",root_path, multi=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFSpliter():\n",
    "    def __init__(self, train_size= 0.8, val_size = 0.2, save = False, seed = 69) -> None:\n",
    "        self.train_size = train_size\n",
    "        self.val_size = val_size\n",
    "        self.save = save\n",
    "        self.seed = seed\n",
    "\n",
    "    def __call__(self, csv_file, root_path):\n",
    "        try:\n",
    "            loc_df = pd.read_csv(os.path.join(root_path,csv_file)).drop(labels=\"Unnamed: 0\", axis = 1)\n",
    "        except:\n",
    "            loc_df = pd.read_csv(os.path.join(root_path,csv_file))\n",
    "        # loc_df = csv_file\n",
    "        patients = loc_df[\"Patient\"].unique()\n",
    "        np.random.seed(self.seed)\n",
    "        np.random.shuffle(patients)\n",
    "        end_idx = round(len(patients)*self.train_size)\n",
    "\n",
    "        train_patients = patients[:end_idx]\n",
    "        val_patients = patients[end_idx:]\n",
    "        \n",
    "        train_df = pd.DataFrame()\n",
    "        for patient in train_patients:\n",
    "            train_df = pd.concat([train_df,loc_df[loc_df[\"Patient\"] == patient]])\n",
    "\n",
    "        val_df = pd.DataFrame()\n",
    "        for patient in val_patients:\n",
    "            val_df = pd.concat([val_df,loc_df[loc_df[\"Patient\"] == patient]])\n",
    "        \n",
    "        val_df.reset_index(inplace=True, drop= True)\n",
    "        train_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        if self.save:\n",
    "            train_df.to_csv(\"train_feats.csv\", encoding= \"utf-8\", index = False)\n",
    "            val_df.to_csv(\"val_feats.csv\", encoding=\"utf-8\", index=False)\n",
    "        print(\"CSVs creados\")\n",
    "        return train_df,val_df\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Masking(channel: np.array, window: int= 150):\n",
    "    '''\n",
    "    Set to zero \n",
    "    Input:  -channel = Numpy array\n",
    "            -window = Number of samples to set to zero\n",
    "    Output: Numpy array masked\n",
    "    '''\n",
    "    channel_size = len(channel)\n",
    "    first = np.random.randint(0,channel_size- window)\n",
    "    masked = channel.copy()\n",
    "    masked[first:first+window] = 0\n",
    "\n",
    "    return masked\n",
    "\n",
    "def DCVoltage(channel : np.array, max_magnitude: float = 0.5):\n",
    "    ''' \n",
    "    Add a DC component between [-max_mangitude, max_magnitude]\n",
    "    Input:  -channel = Numpy array\n",
    "            -max_magnitude = max value to be added\n",
    "    Output: Numpy array \n",
    "    '''\n",
    "    dc_comp = (np.random.random(1)*2 - 1)*max_magnitude\n",
    "    dispaced_channel = channel + dc_comp\n",
    "    return dispaced_channel    \n",
    "\n",
    "def GaussianNoise(channel: np.array, std: float = 0.2):\n",
    "    '''\n",
    "    Add Gaussian Noise with zero mean and std deviation\n",
    "    Input:  -channel = Numpy array\n",
    "            -std = Gaussian std\n",
    "    Output: Channel with additive gaussian noise added\n",
    "    '''\n",
    "    channel_size = len(channel)\n",
    "    noise = np.random.normal(loc = 0, scale= std, size= channel_size)\n",
    "    noisy_channel = channel + noise\n",
    "    return noisy_channel\n",
    "\n",
    "def Time_Shift(channel: np.array, min_shift: int = 0, max_shift: int = 50 ):\n",
    "    ''' \n",
    "    Shifts the channel n samples between min_shift and max_shift using reflection pad\n",
    "    Input:  -channel = Numpy array\n",
    "            -min_shift = Min number of samples to shift\n",
    "            -max_shhift = Max number of samples to shift  \n",
    "    Output: Shifted channel\n",
    "    '''\n",
    "    n_shift = np.random.randint(min_shift,max_shift)\n",
    "    channel_size = len(channel)\n",
    "    padded_array = np.pad(channel,pad_width= n_shift, mode = \"reflect\")\n",
    "    right_left = np.random.choice((0,2))\n",
    "    shifted_array = padded_array[n_shift*right_left:channel_size + n_shift*right_left]\n",
    "    return shifted_array\n",
    "def Amplitude(channel :np.array, max_amplitude: float = 1.5):\n",
    "    '''\n",
    "    Modifies the ampliude of the channel values between [1+max_amplitude,1-max_amplitude]\n",
    "    Input:  -channel = Numpy array\n",
    "            -max_amplitude = Max aplitude to add\n",
    "    Output: Boosted channel\n",
    "    '''\n",
    "    amplitude = 1 + ((np.random.random(1)*2 -1) * max_amplitude)\n",
    "    boosted_channel = channel*amplitude\n",
    "    return boosted_channel\n",
    "\n",
    "def Permutation(channel: np.array, win_samples: int = 500):\n",
    "    '''\n",
    "    Permutates the arrays by secuences of win_samples len\n",
    "    Ensure its divisible by the total len of the array or the len of the output secuence will be wrong\n",
    "    Input:  -channel = Numpu array\n",
    "            -win_samples = Number of samples per secuences (N_sec = len(channel)// win_samples)\n",
    "    Output: Permutated secuence\n",
    "    '''\n",
    "\n",
    "    n_seqs = len(channel)// win_samples\n",
    "    random_idx = np.random.choice(np.arange(0,n_seqs, 1), n_seqs, replace=False ) \n",
    "    permutated = np.concatenate([channel[win_samples*i: win_samples*(i+1)] for i in random_idx])\n",
    "    return permutated\n",
    "def Temporal_Invertion(channel: np.array):\n",
    "    ''' \n",
    "    Return the array reversed\n",
    "    Input:  -channel = Numpy array\n",
    "    Output: Reversed array\n",
    "    '''\n",
    "    reversed = channel[::-1]\n",
    "    return reversed\n",
    "\n",
    "def Negation(channel: np.array):\n",
    "    '''\n",
    "    Inverts the full array\n",
    "    Input: -channel = Numpy array\n",
    "    Output: Inverted array\n",
    "    '''\n",
    "    negated = channel * (-1)\n",
    "    return negated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentation set\n",
    "AUGMENTATIONS = [Negation,\n",
    "                 Time_Shift,\n",
    "                 Amplitude,\n",
    "                 DCVoltage,\n",
    "                 GaussianNoise,\n",
    "                 Temporal_Invertion,\n",
    "                 Permutation,\n",
    "                 Masking]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmentations(nn.Module):\n",
    "    def __init__(self, n_aug, multi = False, augmentations = None) -> None:\n",
    "        self.n_aug = n_aug\n",
    "        self.multi = multi\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "    def __call__(self,batch):\n",
    "        xbar_batch = []\n",
    "        xhat_batch = []\n",
    "\n",
    "        batch = batch.numpy()\n",
    "\n",
    "        for channel in batch:\n",
    "\n",
    "            rbar_idxs = np.random.choice(np.arange(0,len(self.augmentations),1),size=self.n_aug, replace= False)\n",
    "            rhat_idxs = np.random.choice(np.arange(0,len(self.augmentations),1),size=self.n_aug, replace= False)\n",
    "\n",
    "            xbar = channel\n",
    "            xhat = channel\n",
    "            for i in rbar_idxs:\n",
    "                xbar = self.augmentations[i](xbar)\n",
    "                # print(self.augmentations[i])\n",
    "            for j in rhat_idxs:\n",
    "                xhat = self.augmentations[j](xhat)\n",
    "                # print(self.augmentations[j])\n",
    "            xbar_batch.append(torch.from_numpy(xbar.copy()))\n",
    "            xhat_batch.append(torch.from_numpy(xhat.copy()))\n",
    "        \n",
    "        xbar_batch = torch.vstack(xbar_batch)\n",
    "        xhat_batch = torch.vstack(xhat_batch)\n",
    "\n",
    "        return xbar_batch,xhat_batch\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc_df = pd.DataFrame(columns= [\"Patient\", \"Session\",\"N_Win\", \"Dir\"], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"C:\\\\Users\\\\TheSy\\\\Desktop\\\\FinalEL7006\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esta cosa agrega elementos al dataframe vacio, prueba cambiando el primer elemento de la lista \n",
    "#Para agregar distintos pacientes c:\n",
    "# loc_df.loc[len(loc_df)] = [\"aaal\",\"session_id\",1,\"LSTMData-0.001.pt\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVs creados\n"
     ]
    }
   ],
   "source": [
    "spliter = DFSpliter(save=True)\n",
    "train ,val = spliter(\"prep_channels.csv\", root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        Patient Session  N_Win  \\\n",
       " 0      aaaaaaaa    s001      1   \n",
       " 1      aaaaaaaa    s001      1   \n",
       " 2      aaaaaaaa    s001      1   \n",
       " 3      aaaaaaaa    s001      1   \n",
       " 4      aaaaaaaa    s001      1   \n",
       " ...         ...     ...    ...   \n",
       " 12839  aaaaaaab    s003     27   \n",
       " 12840  aaaaaaab    s003     27   \n",
       " 12841  aaaaaaab    s003     27   \n",
       " 12842  aaaaaaab    s003     27   \n",
       " 12843  aaaaaaab    s003     27   \n",
       " \n",
       "                                                      Dir  \n",
       " 0       dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch1.pt  \n",
       " 1       dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch2.pt  \n",
       " 2       dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch3.pt  \n",
       " 3       dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch4.pt  \n",
       " 4       dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch5.pt  \n",
       " ...                                                  ...  \n",
       " 12839  dataper_channel\\aaaaaaab\\aaaaaaab_s003_w27_ch1...  \n",
       " 12840  dataper_channel\\aaaaaaab\\aaaaaaab_s003_w27_ch1...  \n",
       " 12841  dataper_channel\\aaaaaaab\\aaaaaaab_s003_w27_ch1...  \n",
       " 12842  dataper_channel\\aaaaaaab\\aaaaaaab_s003_w27_ch1...  \n",
       " 12843  dataper_channel\\aaaaaaab\\aaaaaaab_s003_w27_ch1...  \n",
       " \n",
       " [12844 rows x 4 columns],\n",
       "       Patient Session  N_Win  \\\n",
       " 0    aaaaaaad    s001      1   \n",
       " 1    aaaaaaad    s001      1   \n",
       " 2    aaaaaaad    s001      1   \n",
       " 3    aaaaaaad    s001      1   \n",
       " 4    aaaaaaad    s001      1   \n",
       " ..        ...     ...    ...   \n",
       " 603  aaaaaaad    s001     32   \n",
       " 604  aaaaaaad    s001     32   \n",
       " 605  aaaaaaad    s001     32   \n",
       " 606  aaaaaaad    s001     32   \n",
       " 607  aaaaaaad    s001     32   \n",
       " \n",
       "                                                    Dir  \n",
       " 0     dataper_channel\\aaaaaaad\\aaaaaaad_s001_w1_ch1.pt  \n",
       " 1     dataper_channel\\aaaaaaad\\aaaaaaad_s001_w1_ch2.pt  \n",
       " 2     dataper_channel\\aaaaaaad\\aaaaaaad_s001_w1_ch3.pt  \n",
       " 3     dataper_channel\\aaaaaaad\\aaaaaaad_s001_w1_ch4.pt  \n",
       " 4     dataper_channel\\aaaaaaad\\aaaaaaad_s001_w1_ch5.pt  \n",
       " ..                                                 ...  \n",
       " 603  dataper_channel\\aaaaaaad\\aaaaaaad_s001_w32_ch1...  \n",
       " 604  dataper_channel\\aaaaaaad\\aaaaaaad_s001_w32_ch1...  \n",
       " 605  dataper_channel\\aaaaaaad\\aaaaaaad_s001_w32_ch1...  \n",
       " 606  dataper_channel\\aaaaaaad\\aaaaaaad_s001_w32_ch1...  \n",
       " 607  dataper_channel\\aaaaaaad\\aaaaaaad_s001_w32_ch1...  \n",
       " \n",
       " [608 rows x 4 columns])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train,val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomEEGDataset(\"prep_channels.csv\",root_path, multi=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4817,  0.7087,  0.6662,  ..., -0.7281, -0.5517, -0.8499],\n",
       "        [ 0.4817,  0.7087,  0.6662,  ..., -0.7281, -0.5517, -0.8499]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader(dataset=dataset,batch_size=4,shuffle=True,num_workers=0, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = Augmentations(3,augmentations=AUGMENTATIONS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
