{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "# from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyFiles.models import Pretext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory created :D\n",
      "Extracting EDF parameters from C:\\Users\\TheSy\\Desktop\\tests\\aaaaaaaa\\s001_2015_12_30\\01_tcp_ar\\aaaaaaaa_s001_t000.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 323839  =      0.000 ...  1264.996 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 70 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 1.00, 70.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 59 - 61 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandstop zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 59.00, 61.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Not setting metadata\n",
      "66 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 66 events and 1001 original time points ...\n",
      "1 bad epochs dropped\n",
      "Dropped 1 epoch: 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Session</th>\n",
       "      <th>N_Win</th>\n",
       "      <th>Dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>1</td>\n",
       "      <td>data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch1.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>1</td>\n",
       "      <td>data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch2.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>1</td>\n",
       "      <td>data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch3.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>1</td>\n",
       "      <td>data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch4.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>1</td>\n",
       "      <td>data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch5.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>64</td>\n",
       "      <td>data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w64_ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>64</td>\n",
       "      <td>data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w64_ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>64</td>\n",
       "      <td>data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w64_ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>64</td>\n",
       "      <td>data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w64_ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>aaaaaaaa</td>\n",
       "      <td>s001</td>\n",
       "      <td>64</td>\n",
       "      <td>data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w64_ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1216 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient Session  N_Win  \\\n",
       "0     aaaaaaaa    s001      1   \n",
       "1     aaaaaaaa    s001      1   \n",
       "2     aaaaaaaa    s001      1   \n",
       "3     aaaaaaaa    s001      1   \n",
       "4     aaaaaaaa    s001      1   \n",
       "...        ...     ...    ...   \n",
       "1211  aaaaaaaa    s001     64   \n",
       "1212  aaaaaaaa    s001     64   \n",
       "1213  aaaaaaaa    s001     64   \n",
       "1214  aaaaaaaa    s001     64   \n",
       "1215  aaaaaaaa    s001     64   \n",
       "\n",
       "                                                    Dir  \n",
       "0     data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch1.pt  \n",
       "1     data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch2.pt  \n",
       "2     data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch3.pt  \n",
       "3     data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch4.pt  \n",
       "4     data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch5.pt  \n",
       "...                                                 ...  \n",
       "1211  data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w64_ch...  \n",
       "1212  data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w64_ch...  \n",
       "1213  data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w64_ch...  \n",
       "1214  data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w64_ch...  \n",
       "1215  data\\per_channel\\aaaaaaaa\\aaaaaaaa_s001_w64_ch...  \n",
       "\n",
       "[1216 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep(\"C:\\\\Users\\\\TheSy\\\\Desktop\\\\tests\", save = True, mode = \"per_channel\", save_dir=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEEGDataset(Dataset):\n",
    "    def __init__(self, csv_file , root_dir , transform = None, multi = False, ):\n",
    "\n",
    "        try:\n",
    "            self.loc_df = pd.read_csv(os.path.join(root_dir,csv_file)).drop(labels=\"Unnamed: 0\", axis = 1)\n",
    "        except:\n",
    "            self.loc_df = pd.read_csv(os.path.join(root_dir,csv_file))\n",
    "        # self.loc_df = loc_df\n",
    "        self.transform = transform\n",
    "        self.root_dir = root_dir\n",
    "        self.multi = multi\n",
    "    def __len__(self,):\n",
    "        return len(self.loc_df)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        eeg_file = os.path.join(self.root_dir,\n",
    "                                self.loc_df.iloc[idx, 3])\n",
    "        eeg = torch.load(eeg_file)\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            ch1 = self.transform(eeg)\n",
    "            ch2 = self.transform(eeg)\n",
    "            return ch1, ch2\n",
    "\n",
    "        return eeg, eeg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"C:\\\\Users\\\\TheSy\\\\Desktop\\\\FinalEL7006\\\\borradores\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = CustomEEGDataset(\"prep_channels.csv\",root_path, multi=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFSpliter():\n",
    "    def __init__(self, train_size= 0.8, val_size = 0.2, save = False, seed = 69) -> None:\n",
    "        self.train_size = train_size\n",
    "        self.val_size = val_size\n",
    "        self.save = save\n",
    "        self.seed = seed\n",
    "\n",
    "    def __call__(self, csv_file, root_path):\n",
    "        try:\n",
    "            loc_df = pd.read_csv(os.path.join(root_path,csv_file)).drop(labels=\"Unnamed: 0\", axis = 1)\n",
    "        except:\n",
    "            loc_df = pd.read_csv(os.path.join(root_path,csv_file))\n",
    "        # loc_df = csv_file\n",
    "        patients = loc_df[\"Patient\"].unique()\n",
    "        np.random.seed(self.seed)\n",
    "        np.random.shuffle(patients)\n",
    "        end_idx = round(len(patients)*self.train_size)\n",
    "\n",
    "        train_patients = patients[:end_idx]\n",
    "        val_patients = patients[end_idx:]\n",
    "        \n",
    "        train_df = pd.DataFrame()\n",
    "        for patient in train_patients:\n",
    "            train_df = pd.concat([train_df,loc_df[loc_df[\"Patient\"] == patient]])\n",
    "\n",
    "        val_df = pd.DataFrame()\n",
    "        for patient in val_patients:\n",
    "            val_df = pd.concat([val_df,loc_df[loc_df[\"Patient\"] == patient]])\n",
    "        \n",
    "        val_df.reset_index(inplace=True, drop= True)\n",
    "        train_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        if self.save:\n",
    "            train_df.to_csv(\"train_feats.csv\", encoding= \"utf-8\", index = False)\n",
    "            val_df.to_csv(\"val_feats.csv\", encoding=\"utf-8\", index=False)\n",
    "        print(\"CSVs creados\")\n",
    "        return train_df,val_df\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Masking(channel: np.array, window: int= 150):\n",
    "    '''\n",
    "    Set to zero \n",
    "    Input:  -channel = Numpy array\n",
    "            -window = Number of samples to set to zero\n",
    "    Output: Numpy array masked\n",
    "    '''\n",
    "    channel_size = len(channel)\n",
    "    first = np.random.randint(0,channel_size- window)\n",
    "    masked = channel.copy()\n",
    "    masked[first:first+window] = 0\n",
    "\n",
    "    return masked\n",
    "\n",
    "def DCVoltage(channel : np.array, max_magnitude: float = 0.5):\n",
    "    ''' \n",
    "    Add a DC component between [-max_mangitude, max_magnitude]\n",
    "    Input:  -channel = Numpy array\n",
    "            -max_magnitude = max value to be added\n",
    "    Output: Numpy array \n",
    "    '''\n",
    "    dc_comp = (np.random.random(1)*2 - 1)*max_magnitude\n",
    "    dispaced_channel = channel + dc_comp\n",
    "    return dispaced_channel    \n",
    "\n",
    "def GaussianNoise(channel: np.array, std: float = 0.2):\n",
    "    '''\n",
    "    Add Gaussian Noise with zero mean and std deviation\n",
    "    Input:  -channel = Numpy array\n",
    "            -std = Gaussian std\n",
    "    Output: Channel with additive gaussian noise added\n",
    "    '''\n",
    "    channel_size = len(channel)\n",
    "    noise = np.random.normal(loc = 0, scale= std, size= channel_size)\n",
    "    noisy_channel = channel + noise\n",
    "    return noisy_channel\n",
    "\n",
    "def Time_Shift(channel: np.array, min_shift: int = 0, max_shift: int = 50 ):\n",
    "    ''' \n",
    "    Shifts the channel n samples between min_shift and max_shift using reflection pad\n",
    "    Input:  -channel = Numpy array\n",
    "            -min_shift = Min number of samples to shift\n",
    "            -max_shhift = Max number of samples to shift  \n",
    "    Output: Shifted channel\n",
    "    '''\n",
    "    n_shift = np.random.randint(min_shift,max_shift)\n",
    "    channel_size = len(channel)\n",
    "    padded_array = np.pad(channel,pad_width= n_shift, mode = \"reflect\")\n",
    "    right_left = np.random.choice((0,2))\n",
    "    shifted_array = padded_array[n_shift*right_left:channel_size + n_shift*right_left]\n",
    "    return shifted_array\n",
    "def Amplitude(channel :np.array, max_amplitude: float = 1.5):\n",
    "    '''\n",
    "    Modifies the ampliude of the channel values between [1+max_amplitude,1-max_amplitude]\n",
    "    Input:  -channel = Numpy array\n",
    "            -max_amplitude = Max aplitude to add\n",
    "    Output: Boosted channel\n",
    "    '''\n",
    "    amplitude = 1 + ((np.random.random(1)*2 -1) * max_amplitude)\n",
    "    boosted_channel = channel*amplitude\n",
    "    return boosted_channel\n",
    "\n",
    "def Permutation(channel: np.array, win_samples: int = 500):\n",
    "    '''\n",
    "    Permutates the arrays by secuences of win_samples len\n",
    "    Ensure its divisible by the total len of the array or the len of the output secuence will be wrong\n",
    "    Input:  -channel = Numpu array\n",
    "            -win_samples = Number of samples per secuences (N_sec = len(channel)// win_samples)\n",
    "    Output: Permutated secuence\n",
    "    '''\n",
    "\n",
    "    n_seqs = len(channel)// win_samples\n",
    "    random_idx = np.random.choice(np.arange(0,n_seqs, 1), n_seqs, replace=False ) \n",
    "    permutated = np.concatenate([channel[win_samples*i: win_samples*(i+1)] for i in random_idx])\n",
    "    return permutated\n",
    "def Temporal_Invertion(channel: np.array):\n",
    "    ''' \n",
    "    Return the array reversed\n",
    "    Input:  -channel = Numpy array\n",
    "    Output: Reversed array\n",
    "    '''\n",
    "    reversed = channel[::-1]\n",
    "    return reversed\n",
    "\n",
    "def Negation(channel: np.array):\n",
    "    '''\n",
    "    Inverts the full array\n",
    "    Input: -channel = Numpy array\n",
    "    Output: Inverted array\n",
    "    '''\n",
    "    negated = channel * (-1)\n",
    "    return negated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentation set\n",
    "AUGMENTATIONS = [Negation,\n",
    "                 Time_Shift,\n",
    "                 Amplitude,\n",
    "                 DCVoltage,\n",
    "                 GaussianNoise,\n",
    "                 Temporal_Invertion,\n",
    "                 Permutation,\n",
    "                 Masking]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Masking(channel: torch.Tensor, window: int= 250):\n",
    "    '''\n",
    "    Set to zero \n",
    "    Input: \\\\\n",
    "    -channel = Tensor \\\\\n",
    "    -window = Number of samples to set to zero\n",
    "    Output: Numpy array masked\n",
    "    '''\n",
    "    channel_size = len(channel)\n",
    "    # print(channel_size)\n",
    "\n",
    "    mask = torch.zeros(window)\n",
    "    first = torch.randint(0,channel_size - window,(1,1))\n",
    "\n",
    "    masked = torch.cat([channel[:first],\n",
    "                        mask,\n",
    "                        channel[first+window:]])\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmentations(nn.Module):\n",
    "    def __init__(self, n_aug, multi = False, augmentations = None) -> None:\n",
    "        self.n_aug = n_aug\n",
    "        self.multi = multi\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "    def __call__(self, channel):\n",
    "\n",
    "        aug_batch = channel\n",
    "        for i in range(self.n_aug):\n",
    "            aug_batch = self.augmentations[i](aug_batch)\n",
    "\n",
    "        return aug_batch\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc_df = pd.DataFrame(columns= [\"Patient\", \"Session\",\"N_Win\", \"Dir\"], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"C:\\\\Users\\\\TheSy\\\\Desktop\\\\FinalEL7006\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esta cosa agrega elementos al dataframe vacio, prueba cambiando el primer elemento de la lista \n",
    "#Para agregar distintos pacientes c:\n",
    "# loc_df.loc[len(loc_df)] = [\"aaal\",\"session_id\",1,\"LSTMData-0.001.pt\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVs creados\n"
     ]
    }
   ],
   "source": [
    "spliter = DFSpliter(save=True)\n",
    "train ,val = spliter(\"prep_channels.csv\", root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        Patient Session  N_Win  \\\n",
       " 0      aaaaaaaa    s001      1   \n",
       " 1      aaaaaaaa    s001      1   \n",
       " 2      aaaaaaaa    s001      1   \n",
       " 3      aaaaaaaa    s001      1   \n",
       " 4      aaaaaaaa    s001      1   \n",
       " ...         ...     ...    ...   \n",
       " 12839  aaaaaaab    s003     27   \n",
       " 12840  aaaaaaab    s003     27   \n",
       " 12841  aaaaaaab    s003     27   \n",
       " 12842  aaaaaaab    s003     27   \n",
       " 12843  aaaaaaab    s003     27   \n",
       " \n",
       "                                                      Dir  \n",
       " 0       dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch1.pt  \n",
       " 1       dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch2.pt  \n",
       " 2       dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch3.pt  \n",
       " 3       dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch4.pt  \n",
       " 4       dataper_channel\\aaaaaaaa\\aaaaaaaa_s001_w1_ch5.pt  \n",
       " ...                                                  ...  \n",
       " 12839  dataper_channel\\aaaaaaab\\aaaaaaab_s003_w27_ch1...  \n",
       " 12840  dataper_channel\\aaaaaaab\\aaaaaaab_s003_w27_ch1...  \n",
       " 12841  dataper_channel\\aaaaaaab\\aaaaaaab_s003_w27_ch1...  \n",
       " 12842  dataper_channel\\aaaaaaab\\aaaaaaab_s003_w27_ch1...  \n",
       " 12843  dataper_channel\\aaaaaaab\\aaaaaaab_s003_w27_ch1...  \n",
       " \n",
       " [12844 rows x 4 columns],\n",
       "       Patient Session  N_Win  \\\n",
       " 0    aaaaaaad    s001      1   \n",
       " 1    aaaaaaad    s001      1   \n",
       " 2    aaaaaaad    s001      1   \n",
       " 3    aaaaaaad    s001      1   \n",
       " 4    aaaaaaad    s001      1   \n",
       " ..        ...     ...    ...   \n",
       " 603  aaaaaaad    s001     32   \n",
       " 604  aaaaaaad    s001     32   \n",
       " 605  aaaaaaad    s001     32   \n",
       " 606  aaaaaaad    s001     32   \n",
       " 607  aaaaaaad    s001     32   \n",
       " \n",
       "                                                    Dir  \n",
       " 0     dataper_channel\\aaaaaaad\\aaaaaaad_s001_w1_ch1.pt  \n",
       " 1     dataper_channel\\aaaaaaad\\aaaaaaad_s001_w1_ch2.pt  \n",
       " 2     dataper_channel\\aaaaaaad\\aaaaaaad_s001_w1_ch3.pt  \n",
       " 3     dataper_channel\\aaaaaaad\\aaaaaaad_s001_w1_ch4.pt  \n",
       " 4     dataper_channel\\aaaaaaad\\aaaaaaad_s001_w1_ch5.pt  \n",
       " ..                                                 ...  \n",
       " 603  dataper_channel\\aaaaaaad\\aaaaaaad_s001_w32_ch1...  \n",
       " 604  dataper_channel\\aaaaaaad\\aaaaaaad_s001_w32_ch1...  \n",
       " 605  dataper_channel\\aaaaaaad\\aaaaaaad_s001_w32_ch1...  \n",
       " 606  dataper_channel\\aaaaaaad\\aaaaaaad_s001_w32_ch1...  \n",
       " 607  dataper_channel\\aaaaaaad\\aaaaaaad_s001_w32_ch1...  \n",
       " \n",
       " [608 rows x 4 columns])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train,val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Augmentations(1,False,[Masking])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomEEGDataset(\"prep_channels.csv\",root_path, multi=False, transform= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader(dataset=dataset,batch_size=4,shuffle=False,num_workers=0, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pretext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1000])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.cat([dataset[0][0].unsqueeze(dim = 0).unsqueeze(dim = 1),dataset[0][0].unsqueeze(dim = 0).unsqueeze(dim = 1)], dim = 0)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [100, 1, 128], expected input[1, 2, 1127] to have 1 channels, but got 2 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\TheSy\\Desktop\\FinalEL7006\\Custom.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model(a)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\TheSy\\Desktop\\FinalEL7006\\pyFiles\\models.py:230\u001b[0m, in \u001b[0;36mPretext.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m--> 230\u001b[0m     first \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[0;32m    231\u001b[0m     end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprojector(first)\n\u001b[0;32m    232\u001b[0m     \u001b[39mreturn\u001b[39;00m end\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\TheSy\\Desktop\\FinalEL7006\\pyFiles\\models.py:74\u001b[0m, in \u001b[0;36mConvolutional_Enc.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     73\u001b[0m     \u001b[39m# Pass through convolutionals\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m     xc1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[0;32m     75\u001b[0m     xc2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)\n\u001b[0;32m     76\u001b[0m     xc3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [100, 1, 128], expected input[1, 2, 1127] to have 1 channels, but got 2 channels instead"
     ]
    }
   ],
   "source": [
    "model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n",
      "torch.Size([4, 1, 1000])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\TheSy\\Desktop\\FinalEL7006\\Custom.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     aug1, aug2 \u001b[39m=\u001b[39m batch\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(aug1\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32mc:\\Users\\TheSy\\Desktop\\FinalEL7006\\Custom.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m eeg_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_dir,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m                         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc_df\u001b[39m.\u001b[39miloc[idx, \u001b[39m3\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# print(eeg_file.shape)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m# eeg = torch.from_numpy(torch.load(eeg_file)) # [0][0]\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m eeg \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(eeg_file)\u001b[39m.\u001b[39munsqueeze(dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# print(eeg.shape)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m#     if self.multi:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m#         eeg= eeg.unsqueeze(0)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m#     batch.append(eeg) \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# bat = torch.vstack(batch)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TheSy/Desktop/FinalEL7006/Custom.ipynb#X26sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    789\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 791\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    792\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    793\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    794\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    796\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 271\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    272\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    273\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 252\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(data):\n",
    "    aug1, aug2 = batch\n",
    "    \n",
    "    print(aug1.shape)\n",
    "    # print(aug2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = Augmentations(3,augmentations=AUGMENTATIONS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
