{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.system('export CUDA_VISIBLE_DEVICES=1')\n",
    "from training import *\n",
    "from models import *\n",
    "from dataprep import *\n",
    "from dataprep2 import *\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from losses import BarlowTwins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "torch.set_default_dtype(torch.float)\n",
    "# os.system('export CUDA_VISIBLE_DEVICES=2')\n",
    "\n",
    "# os.system('export CUDA_VISIBLE_DEVICES=1')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep(\"/home/el7006-23-t4/dataset/tuh_eeg\", mode = \"per_channel\", save = True, save_dir = \"/home/el7006-23-t4/data\",)\n",
    "# prep(\"D:\\\\OneDrive\\\\OneDrive - Universidad de Chile\\\\Semestre X\\\\Inteligencia\\\\Proyecto\\\\dataset\\\\tuh_eeg\", mode = \"per_channel\", save = True, save_dir = \"data\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliter = DFSpliter(save = True)\n",
    "# train_df, val_df = spliter(\"prep_channels.csv\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomEEGDataset(\"train_feats.csv\", root_dir = \"\", multi = False)\n",
    "val_dataset = CustomEEGDataset(\"val_feats.csv\", root_dir = \"\", multi = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_dataset, batch_size = 20, shuffle = True, num_workers = 0)\n",
    "valloader = DataLoader(val_dataset, batch_size = 20, shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = Augmentations(1, multi = False, augmentations = AUGMENTATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch nro 1/30\n",
      "Iter: 1/1305, Loss:9999.416015625\n",
      "Iter: 2/1305, Loss:9999.3359375\n",
      "Iter: 3/1305, Loss:9998.8623046875\n",
      "Iter: 4/1305, Loss:9998.7724609375\n",
      "Iter: 5/1305, Loss:9998.58203125\n",
      "Iter: 6/1305, Loss:9998.2958984375\n",
      "Iter: 7/1305, Loss:9998.658203125\n",
      "Iter: 8/1305, Loss:9998.9072265625\n",
      "Iter: 9/1305, Loss:9999.0078125\n",
      "Iter: 10/1305, Loss:9999.455078125\n",
      "Iter: 11/1305, Loss:9998.4111328125\n",
      "Iter: 12/1305, Loss:9998.833984375\n",
      "Iter: 13/1305, Loss:9998.4150390625\n",
      "Iter: 14/1305, Loss:9998.5068359375\n",
      "Iter: 15/1305, Loss:9998.4052734375\n",
      "Iter: 16/1305, Loss:9998.61328125\n",
      "Iter: 17/1305, Loss:9998.123046875\n",
      "Iter: 18/1305, Loss:9998.3349609375\n",
      "Iter: 19/1305, Loss:9999.3720703125\n",
      "Iter: 20/1305, Loss:9998.3759765625\n",
      "Iter: 21/1305, Loss:9998.6416015625\n",
      "Iter: 22/1305, Loss:9998.3203125\n",
      "Iter: 23/1305, Loss:9998.7587890625\n",
      "Iter: 24/1305, Loss:9998.716796875\n",
      "Iter: 25/1305, Loss:9998.4794921875\n",
      "Iter: 26/1305, Loss:9998.8515625\n",
      "Iter: 27/1305, Loss:9998.35546875\n",
      "Iter: 28/1305, Loss:9998.310546875\n",
      "Iter: 29/1305, Loss:9998.283203125\n",
      "Iter: 30/1305, Loss:9998.6328125\n",
      "Validating, Val loss = 9998.1923828125\n",
      "Iter: 31/1305, Loss:9998.4580078125\n",
      "Iter: 32/1305, Loss:9998.23046875\n",
      "Iter: 33/1305, Loss:9998.2099609375\n",
      "Iter: 34/1305, Loss:9998.185546875\n",
      "Iter: 35/1305, Loss:9998.1640625\n",
      "Iter: 36/1305, Loss:9998.068359375\n",
      "Iter: 37/1305, Loss:9998.005859375\n",
      "Iter: 38/1305, Loss:9998.04296875\n",
      "Iter: 39/1305, Loss:9998.109375\n",
      "Iter: 40/1305, Loss:9998.0107421875\n",
      "Iter: 41/1305, Loss:9998.0615234375\n",
      "Iter: 42/1305, Loss:9998.0068359375\n",
      "Iter: 43/1305, Loss:9998.0107421875\n",
      "Iter: 44/1305, Loss:9998.212890625\n",
      "Iter: 45/1305, Loss:9998.0068359375\n",
      "Iter: 46/1305, Loss:9998.0087890625\n",
      "Iter: 47/1305, Loss:9998.0068359375\n",
      "Iter: 48/1305, Loss:9998.005859375\n",
      "Iter: 49/1305, Loss:9998.0107421875\n",
      "Iter: 50/1305, Loss:9998.0205078125\n",
      "Iter: 51/1305, Loss:9998.0107421875\n",
      "Iter: 52/1305, Loss:9998.0048828125\n",
      "Iter: 53/1305, Loss:9998.1318359375\n",
      "Iter: 54/1305, Loss:9998.0048828125\n",
      "Iter: 55/1305, Loss:9998.0048828125\n",
      "Iter: 56/1305, Loss:9998.005859375\n",
      "Iter: 57/1305, Loss:9998.0048828125\n",
      "Iter: 58/1305, Loss:9998.005859375\n",
      "Iter: 59/1305, Loss:9998.0087890625\n",
      "Iter: 60/1305, Loss:9998.0048828125\n",
      "Validating, Val loss = 9998.00390625\n",
      "Iter: 61/1305, Loss:9998.0068359375\n",
      "Iter: 62/1305, Loss:9998.0048828125\n",
      "Iter: 63/1305, Loss:9998.0048828125\n",
      "Iter: 64/1305, Loss:9998.0068359375\n",
      "Iter: 65/1305, Loss:9998.0068359375\n",
      "Iter: 66/1305, Loss:9998.0048828125\n",
      "Iter: 67/1305, Loss:9998.0048828125\n",
      "Iter: 68/1305, Loss:9998.0048828125\n",
      "Iter: 69/1305, Loss:9998.0048828125\n",
      "Iter: 70/1305, Loss:9998.0048828125\n",
      "Iter: 71/1305, Loss:9998.0048828125\n",
      "Iter: 72/1305, Loss:9998.0048828125\n",
      "Iter: 73/1305, Loss:9998.0068359375\n",
      "Iter: 74/1305, Loss:9998.0048828125\n",
      "Iter: 75/1305, Loss:9998.0048828125\n",
      "Iter: 76/1305, Loss:9998.0048828125\n",
      "Iter: 77/1305, Loss:9998.0048828125\n",
      "Iter: 78/1305, Loss:9998.0048828125\n",
      "Iter: 79/1305, Loss:9998.0048828125\n",
      "Iter: 80/1305, Loss:9998.0048828125\n",
      "Iter: 81/1305, Loss:9998.0048828125\n",
      "Iter: 82/1305, Loss:9998.0048828125\n",
      "Iter: 83/1305, Loss:9998.0078125\n",
      "Iter: 84/1305, Loss:9998.0048828125\n",
      "Iter: 85/1305, Loss:9998.005859375\n",
      "Iter: 86/1305, Loss:9998.0048828125\n",
      "Iter: 87/1305, Loss:9998.0048828125\n",
      "Iter: 88/1305, Loss:9998.0048828125\n",
      "Iter: 89/1305, Loss:9998.0048828125\n",
      "Iter: 90/1305, Loss:9998.0048828125\n",
      "Validating, Val loss = 9998.001953125\n",
      "Iter: 91/1305, Loss:9998.0048828125\n",
      "Iter: 92/1305, Loss:9998.0048828125\n",
      "Iter: 93/1305, Loss:9998.0048828125\n",
      "Iter: 94/1305, Loss:9998.0048828125\n",
      "Iter: 95/1305, Loss:9998.0048828125\n",
      "Iter: 96/1305, Loss:9998.0048828125\n",
      "Iter: 97/1305, Loss:9998.0048828125\n",
      "Iter: 98/1305, Loss:9998.0048828125\n",
      "Iter: 99/1305, Loss:9998.0048828125\n",
      "Iter: 100/1305, Loss:9998.0048828125\n",
      "Iter: 101/1305, Loss:9998.0048828125\n",
      "Iter: 102/1305, Loss:9998.0048828125\n",
      "Iter: 103/1305, Loss:9998.0048828125\n",
      "Iter: 104/1305, Loss:9998.0048828125\n",
      "Iter: 105/1305, Loss:9998.0048828125\n",
      "Iter: 106/1305, Loss:9998.0048828125\n",
      "Iter: 107/1305, Loss:9998.0048828125\n",
      "Iter: 108/1305, Loss:9998.0048828125\n",
      "Iter: 109/1305, Loss:9998.0048828125\n",
      "Iter: 110/1305, Loss:9998.0048828125\n",
      "Iter: 111/1305, Loss:9998.0048828125\n",
      "Iter: 112/1305, Loss:9998.0048828125\n",
      "Iter: 113/1305, Loss:9998.0048828125\n",
      "Iter: 114/1305, Loss:9998.0048828125\n",
      "Iter: 115/1305, Loss:9998.0048828125\n",
      "Iter: 116/1305, Loss:9998.0048828125\n",
      "Iter: 117/1305, Loss:9998.0048828125\n",
      "Iter: 118/1305, Loss:9998.0048828125\n",
      "Iter: 119/1305, Loss:9998.0048828125\n",
      "Iter: 120/1305, Loss:9998.0048828125\n",
      "Validating, Val loss = 9998.001953125\n",
      "Iter: 121/1305, Loss:9998.0048828125\n",
      "Iter: 122/1305, Loss:9998.0048828125\n",
      "Iter: 123/1305, Loss:9998.0048828125\n",
      "Iter: 124/1305, Loss:9998.0048828125\n",
      "Iter: 125/1305, Loss:9998.0048828125\n",
      "Iter: 126/1305, Loss:9998.0048828125\n",
      "Iter: 127/1305, Loss:9998.0048828125\n",
      "Iter: 128/1305, Loss:9998.0048828125\n",
      "Iter: 129/1305, Loss:9998.0048828125\n",
      "Iter: 130/1305, Loss:9998.0048828125\n",
      "Iter: 131/1305, Loss:9998.005859375\n",
      "Iter: 132/1305, Loss:9998.0048828125\n",
      "Iter: 133/1305, Loss:9998.005859375\n",
      "Iter: 134/1305, Loss:9998.0048828125\n",
      "Iter: 135/1305, Loss:9998.0048828125\n",
      "Iter: 136/1305, Loss:9998.0048828125\n",
      "Iter: 137/1305, Loss:9998.0048828125\n",
      "Iter: 138/1305, Loss:9998.0048828125\n",
      "Iter: 139/1305, Loss:9998.0048828125\n",
      "Iter: 140/1305, Loss:9998.0048828125\n",
      "Iter: 141/1305, Loss:9998.0048828125\n",
      "Iter: 142/1305, Loss:9998.0048828125\n",
      "Iter: 143/1305, Loss:9998.0048828125\n",
      "Iter: 144/1305, Loss:9998.005859375\n",
      "Iter: 145/1305, Loss:9998.0048828125\n",
      "Iter: 146/1305, Loss:9998.0048828125\n",
      "Iter: 147/1305, Loss:9998.005859375\n",
      "Iter: 148/1305, Loss:9998.0048828125\n",
      "Iter: 149/1305, Loss:9998.0048828125\n",
      "Iter: 150/1305, Loss:9998.0048828125\n",
      "Validating, Val loss = 9998.001953125\n",
      "Iter: 151/1305, Loss:9998.0048828125\n",
      "Iter: 152/1305, Loss:9998.005859375\n",
      "Iter: 153/1305, Loss:9998.0048828125\n",
      "Iter: 154/1305, Loss:9998.0048828125\n",
      "Iter: 155/1305, Loss:9998.0048828125\n",
      "Iter: 156/1305, Loss:9998.005859375\n",
      "Iter: 157/1305, Loss:9998.0048828125\n",
      "Iter: 158/1305, Loss:9998.0048828125\n",
      "Iter: 159/1305, Loss:9998.0048828125\n",
      "Iter: 160/1305, Loss:9998.0048828125\n",
      "Iter: 161/1305, Loss:9998.0048828125\n",
      "Iter: 162/1305, Loss:9998.0048828125\n",
      "Iter: 163/1305, Loss:9998.0048828125\n",
      "Iter: 164/1305, Loss:9998.0048828125\n",
      "Iter: 165/1305, Loss:9998.0048828125\n",
      "Iter: 166/1305, Loss:9998.0048828125\n",
      "Iter: 167/1305, Loss:9998.0048828125\n",
      "Iter: 168/1305, Loss:9998.0048828125\n",
      "Iter: 169/1305, Loss:9998.0048828125\n",
      "Iter: 170/1305, Loss:9998.0048828125\n",
      "Iter: 171/1305, Loss:9998.005859375\n",
      "Iter: 172/1305, Loss:9998.0048828125\n",
      "Iter: 173/1305, Loss:9998.0048828125\n",
      "Iter: 174/1305, Loss:9998.0048828125\n",
      "Iter: 175/1305, Loss:9998.0048828125\n",
      "Iter: 176/1305, Loss:9998.0048828125\n",
      "Iter: 177/1305, Loss:9998.0048828125\n",
      "Iter: 178/1305, Loss:9998.0048828125\n",
      "Iter: 179/1305, Loss:9998.0048828125\n",
      "Iter: 180/1305, Loss:9998.0048828125\n",
      "Validating, Val loss = 9998.001953125\n",
      "Iter: 181/1305, Loss:9998.0048828125\n",
      "Iter: 182/1305, Loss:9998.0048828125\n",
      "Iter: 183/1305, Loss:9998.0048828125\n",
      "Iter: 184/1305, Loss:9998.0048828125\n",
      "Iter: 185/1305, Loss:9998.0048828125\n",
      "Iter: 186/1305, Loss:9998.0048828125\n",
      "Iter: 187/1305, Loss:9998.0048828125\n",
      "Iter: 188/1305, Loss:9998.0048828125\n",
      "Iter: 189/1305, Loss:9998.0048828125\n",
      "Iter: 190/1305, Loss:9998.005859375\n",
      "Iter: 191/1305, Loss:9998.005859375\n",
      "Iter: 192/1305, Loss:9998.0048828125\n",
      "Iter: 193/1305, Loss:9998.0048828125\n",
      "Iter: 194/1305, Loss:9998.0048828125\n",
      "Iter: 195/1305, Loss:9998.0048828125\n",
      "Iter: 196/1305, Loss:9998.0048828125\n",
      "Iter: 197/1305, Loss:9998.0048828125\n",
      "Iter: 198/1305, Loss:9998.0048828125\n",
      "Iter: 199/1305, Loss:9998.0048828125\n",
      "Iter: 200/1305, Loss:9998.0048828125\n",
      "Iter: 201/1305, Loss:9998.0048828125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\GitHub\\FinalEL7006\\trainingBT.ipynb Cell 11\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/FinalEL7006/trainingBT.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr \u001b[39m=\u001b[39m \u001b[39m0.00005\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/FinalEL7006/trainingBT.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# optimizer = torch.optim.SGD(model.parameters(), lr = 0.0002, momentum = 0.9, weight_decay=0.0002)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/FinalEL7006/trainingBT.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# dataset = torch.load(\"test_batch.pt\")\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/FinalEL7006/trainingBT.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# data = (dataset, dataset)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/GitHub/FinalEL7006/trainingBT.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m pretext_train(model, \u001b[39m30\u001b[39m, trainloader, valloader, criterion, optimizer, aug, each \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, state \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mBT\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\GitHub\\FinalEL7006\\training.py:98\u001b[0m, in \u001b[0;36mpretext_train\u001b[1;34m(model, epochs, train_loader, val_loader, criterion, optimizer, augmentation, each, state, name)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch nro \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[39m# Train\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m train_loss, vloss \u001b[39m=\u001b[39m pretrain_epoch(model, train_loader, val_loader, criterion, optimizer, augmentation)\n\u001b[0;32m     99\u001b[0m \u001b[39m# Val\u001b[39;00m\n\u001b[0;32m    100\u001b[0m val_loss \u001b[39m=\u001b[39m prevalidate(model, val_loader, criterion, augmentation)\n",
      "File \u001b[1;32md:\\GitHub\\FinalEL7006\\training.py:64\u001b[0m, in \u001b[0;36mpretrain_epoch\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, augmentation)\u001b[0m\n\u001b[0;32m     62\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     63\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> 64\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIter: \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(train_loader)\u001b[39m}\u001b[39;00m\u001b[39m, Loss:\u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m lossSum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n\u001b[0;32m     66\u001b[0m iters \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\borja\\miniconda3\\envs\\neuron\\Lib\\site-packages\\torch\\_tensor.py:872\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[1;34m(self, format_spec)\u001b[0m\n\u001b[0;32m    870\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m\u001b[39m__format__\u001b[39m, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, format_spec)\n\u001b[0;32m    871\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_meta \u001b[39mand\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39mis\u001b[39;00m Tensor:\n\u001b[1;32m--> 872\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem()\u001b[39m.\u001b[39m\u001b[39m__format__\u001b[39m(format_spec)\n\u001b[0;32m    873\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__format__\u001b[39m(\u001b[39mself\u001b[39m, format_spec)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Pretext_BT(out_size=10, mlp=True)\n",
    "criterion = BarlowTwins(0.005)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.00005)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr = 0.0002, momentum = 0.9, weight_decay=0.0002)\n",
    "# dataset = torch.load(\"test_batch.pt\")\n",
    "# data = (dataset, dataset)\n",
    "pretext_train(model, 30, trainloader, valloader, criterion, optimizer, aug, each = 2, state = None, name = \"BT\")\n",
    "# pretrain_epoch(model, trainloader, trainloader, InfoNceLoss(), torch.optim.Adam(model.parameters()))\n",
    "# perdida = preloss(model, (x1, x2), InfoNceLoss())\n",
    "# print(dataset[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Downstream()\n",
    "# dataset = torch.load(\"test_batch_2.pt\")\n",
    "# x1 = dataset[0]\n",
    "\n",
    "# y1 = torch.ones((19))\n",
    "\n",
    "# downtrain_epoch(model, ((x1, y1), (x1, y1)), criterion = nn.CrossEntropyLoss(), optimizer = torch.optim.Adam(model.parameters(Classifier)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
